{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepom.bionano_utils import MoleculeSelector\n",
    "\n",
    "selector = MoleculeSelector()\n",
    "selector.top_mol_num = 10\n",
    "selector.select_molecules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Yevgeni's part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.selected[2].plot_bnx_item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepom.bionano_compare import BionanoCompare\n",
    " \n",
    "compare = BionanoCompare()\n",
    "compare.read_cmap()\n",
    "compare.make_refs()\n",
    "compare.refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepom.config import Config\n",
    "from deepom.localizer import LocalizerModule\n",
    "import monai\n",
    "\n",
    "localizer_module = LocalizerModule()\n",
    "localizer_module.checkpoint_search_dir = Config.CHECKPOINT_SEARCH_DIR\n",
    "localizer_module.load_checkpoint = True\n",
    "localizer_module.init_ensure_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import eventplot, imshow, figure, xlim\n",
    "i=3\n",
    "#good molecules: 0,7,6\n",
    "figure(figsize=(30, 3))\n",
    "image_input = selector.selected[i].bionano_image.segment_image[0]\n",
    "target_width = localizer_module.image_channels\n",
    "source_width = image_input.shape[0] // 2 + 1\n",
    "image_input = image_input[source_width - target_width // 2: source_width + target_width // 2 + 1]\n",
    "imshow(image_input, aspect=\"auto\", cmap=\"gray\")\n",
    "inference_item = localizer_module.inference_item(image_input)\n",
    "eventplot([inference_item.loc_pred, selector.selected[i].locs / 375], colors=[\"b\", \"r\"])\n",
    "# xlim([0, 500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_item.loc_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.selected[i].bionano_image.segment_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from deepom.aligner import Aligner\n",
    "from deepom.my_utils import overlap_percentage\n",
    "import numpy as np\n",
    "\n",
    "ref_id = selector.selected[i].xmap_item.ref_id\n",
    "aligner_reg = Aligner()\n",
    "aligner_reg.align_params = {}\n",
    "\n",
    "aligner_rev = Aligner()\n",
    "aligner_rev.align_params = {}\n",
    "\n",
    "qry = inference_item.loc_pred * 335\n",
    "\n",
    "inverted_qry = np.sort((inference_item.loc_pred[-1] - inference_item.loc_pred)*335) #not sure, need to make sure its correct\n",
    "\n",
    "aligner_reg.make_alignment(qry=qry, ref=compare.refs[ref_id])\n",
    "selector.selected[i].xmap_item.ref_lims, aligner_reg.alignment_ref[[0, -1]] # aligner.alignment_qry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "aligner_rev.make_alignment(qry=inverted_qry, ref=compare.refs[ref_id])\n",
    "selector.selected[i].xmap_item.ref_lims, aligner_rev.alignment_ref[[0, -1]], # aligner.alignment_qry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "regular_overlap = overlap_percentage(selector.selected[i].xmap_item.ref_lims, aligner_reg.alignment_ref[[0, -1]])\n",
    "reverse_overlap = overlap_percentage(selector.selected[i].xmap_item.ref_lims, aligner_rev.alignment_ref[[0, -1]])\n",
    "\n",
    "aligner = aligner_reg if regular_overlap > reverse_overlap else aligner_rev\n",
    "\n",
    "regular_overlap*100, reverse_overlap*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from scipy.interpolate import interp1d\n",
    "from deepom.my_utils import getAligner , get_scaler_from_aligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = get_scaler_from_aligner(aligner)\n",
    "\n",
    "z = aligner.alignment_ref\n",
    "y = (z-z[0]) / (scaler*335)\n",
    "y = y+aligner.alignment_qry[0] /335\n",
    "x = aligner.alignment_qry/335\n",
    "f = interp1d(x=y,y=x)\n",
    "\n",
    "# a = numpy.zeros_like(aligner.alignment_ref)\n",
    "# b = numpy.zeros_like(aligner.alignment_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = scaler = get_scaler_from_aligner(aligner_rev)\n",
    "\n",
    "# z = aligner_rev.alignment_ref\n",
    "# y = (z-z[0]) / (scaler*335)\n",
    "# y = y+aligner_rev.alignment_qry[0] /335\n",
    "# x = aligner_rev.alignment_qry/335\n",
    "# f = interp1d(x=y,y=x)\n",
    "\n",
    "# a = numpy.zeros_like(aligner.alignment_ref)\n",
    "# b = numpy.zeros_like(aligner.alignment_ref)\n",
    "\n",
    "# ref = compare.refs[ref_id]\n",
    "# start, end = aligner_rev.alignment_ref[[0, -1]]\n",
    "# start_index = np.argmax(ref >= start)\n",
    "# end_index = np.argmin(ref <= end)\n",
    "# ref_crop = ref[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = compare.refs[ref_id]\n",
    "start, end = aligner.alignment_ref[[0, -1]]\n",
    "start_index = np.argmax(ref >= start)\n",
    "end_index = np.argmin(ref <= end)\n",
    "ref_crop = ref[start_index:end_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_hat = (ref_crop-ref_crop[0]) / (scaler*335)\n",
    "z_hat = z_hat+x[0]\n",
    "y_hat = f(z_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(30, 3))\n",
    "image_input = selector.selected[i].bionano_image.segment_image[0]\n",
    "target_width = localizer_module.image_channels\n",
    "source_width = image_input.shape[0] // 2 + 1\n",
    "image_input = image_input[source_width - target_width // 2: source_width + target_width // 2 + 1]\n",
    "imshow(image_input, aspect=\"auto\", cmap=\"gray\")\n",
    "eventplot([inference_item.loc_pred, x,y_hat], colors=[\"g\", \"b\", \"r\"])\n",
    "xlim([0, 800])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Our Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepom.utils import Config\n",
    "from deepom.bionano_compare import DataPrep\n",
    "from deepom.bionano_utils import BNXItemCrop, BionanoFileData\n",
    "from numpy.random import default_rng\n",
    "from deepom.localizer import LocalizerModule\n",
    "from deepom.aligner import Aligner\n",
    "from deepom.my_utils import getAligner\n",
    "from matplotlib.pyplot import eventplot, imshow, figure, xlim\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tnrange , tqdm_notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepom.config import Config\n",
    "from deepom.localizer import LocalizerModule\n",
    "import monai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_size_bp = 50  *1000\n",
    "crop_size = int(crop_size_bp / Config.BIONANO_NOMINAL_SCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localizer_module = LocalizerModule()\n",
    "localizer_module.checkpoint_search_dir = Config.CHECKPOINT_SEARCH_DIR\n",
    "localizer_module.load_checkpoint = True\n",
    "localizer_module.init_ensure_module()\n",
    "localizer_module.rng = default_rng(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap_file_data = BionanoFileData()\n",
    "cmap_file_data.file = Config.REF_CMAP_FILE\n",
    "cmap_file_data.read_bionano_file()\n",
    "\n",
    "refs = Series({\n",
    "    ref_id: ref_df[ref_df[\"LabelChannel\"] == 1][\"Position\"].values\n",
    "    for ref_id, ref_df in cmap_file_data.file_df.groupby(\"CMapId\")\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over selected molecules, crop localize and align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = default_rng(seed=42)\n",
    "mol_ranks = dict.fromkeys(range(24),0)\n",
    "\n",
    "for i, mol in tqdm_notebook(enumerate(selector.selected)):\n",
    "\n",
    "    \n",
    "    image_len = mol.bionano_image.segment_image.shape[-1]\n",
    "    start = rng.integers(0,image_len - crop_size)\n",
    "    stop = start + crop_size\n",
    "    \n",
    "    segment_image = mol.bionano_image.segment_image[...,start: stop]\n",
    "    crop = BNXItemCrop(mol, (start, stop), i)\n",
    "    crop.crop_size_pixels = crop_size\n",
    "    crop.crop_size_bp = crop_size_bp\n",
    "    crop.segment_image = segment_image\n",
    "    \n",
    "    # finished croping image. moving to locolaizer\n",
    "    \n",
    "    figure(figsize=(30, 3))\n",
    "    image_input = crop.segment_image[0]\n",
    "    target_width = localizer_module.image_channels\n",
    "    source_width = image_input.shape[0] // 2 + 1\n",
    "    image_input = image_input[source_width - target_width // 2: source_width + target_width // 2 + 1]\n",
    "    # imshow(image_input, aspect=\"auto\", cmap=\"gray\")\n",
    "    inference_item = localizer_module.inference_item(image_input)\n",
    "    # eventplot([inference_item.loc_pred, selector.selected[0].locs / 375], colors=[\"b\", \"r\"])\n",
    "    # xlim([0, 50])\n",
    "    \n",
    "    # run analyzer for each molecule, saving all results\n",
    "    qry = inference_item.loc_pred * 335\n",
    "    inverted_qry = np.sort((stop - inference_item.loc_pred)*335) #not sure, need to make sure its correct\n",
    "   \n",
    "\n",
    "    \n",
    "    len_ref = range(1,len(refs)+1)\n",
    "    scores = {}\n",
    "    for j in tqdm_notebook(len_ref,desc = str(i+1)):\n",
    "        \n",
    "        aligner1 = getAligner()\n",
    "        aligner1.make_alignment(qry=qry, ref=refs[j])\n",
    "        score = aligner1.score\n",
    "        \n",
    "        aligner2 = getAligner()\n",
    "        aligner2.make_alignment(qry=inverted_qry, ref=refs[j])\n",
    "        \n",
    "        scores[str(j)] = max(score , aligner2.score)\n",
    "        scores[str(j)] = score\n",
    "\n",
    "    scores = dict(sorted(scores.items(), key=lambda score: -score[1]))\n",
    "    mol_rank = list(scores.keys()).index(str(mol.xmap_item.ref_id))\n",
    "    mol_ranks[mol_rank] += 1 \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_ranks[0]/sum(mol_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localizer_module.image_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2 + 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ba88cba0bd1684bf681f0a514929985c4631defba69dd57c081f0ebc100d81ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
